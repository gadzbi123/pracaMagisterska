\chapter{Badania}

 

%Rozdział przedstawia przeprowadzone badania. Jest to zasadnicza część i~musi wyraźnie dominować w~pracy.
%Badania i analizę wyników należy przeprowadzić, tak jak jest przyjęte w środowisku naukowym (na przykład korzystanie z danych benchmarkowych, walidacja krzyżowa, zapewnienie powtarzalności testów itd). 
%
%\section{Metodyka badań}
%
%\begin{itemize}
%\item opis metodyki badań
%\item opis stanowiska badawczego (opis interfejsu aplikacji badawczych -- w~załączniku)
%\end{itemize}
%
%
%\section{Zbiory danych}
%
%\begin{itemize}
%\item opis danych
%\end{itemize}
%
%
%\section{Wyniki}
%
%\begin{itemize}
%\item prezentacja wyników, opracowanie i poszerzona dyskusja  wyników, wnioski
%\end{itemize}
%
% 
%\begin{table}
%\centering
%\caption{Opis tabeli nad nią.}
%\label{id:tab:wyniki}
%\begin{tabular}{rrrrrrrr}
%\toprule
%	         &                                     \multicolumn{7}{c}{metoda}                                      \\
%	         \cmidrule{2-8}
%	         &         &         &        \multicolumn{3}{c}{alg. 3}        & \multicolumn{2}{c}{alg. 4, $\gamma = 2$} \\
%	         \cmidrule(r){4-6}\cmidrule(r){7-8}
%	$\zeta$ &     alg. 1 &   alg. 2 & $\alpha= 1.5$ & $\alpha= 2$ & $\alpha= 3$ &   $\beta = 0.1$  &   $\beta = -0.1$ \\
%\midrule
%	       0 &  8.3250 & 1.45305 &       7.5791 &    14.8517 &    20.0028 & 1.16396 &                       1.1365 \\
%	       5 &  0.6111 & 2.27126 &       6.9952 &    13.8560 &    18.6064 & 1.18659 &                       1.1630 \\
%	      10 & 11.6126 & 2.69218 &       6.2520 &    12.5202 &    16.8278 & 1.23180 &                       1.2045 \\
%	      15 &  0.5665 & 2.95046 &       5.7753 &    11.4588 &    15.4837 & 1.25131 &                       1.2614 \\
%	      20 & 15.8728 & 3.07225 &       5.3071 &    10.3935 &    13.8738 & 1.25307 &                       1.2217 \\
%	      25 &  0.9791 & 3.19034 &       5.4575 &     9.9533 &    13.0721 & 1.27104 &                       1.2640 \\
%	      30 &  2.0228 & 3.27474 &       5.7461 &     9.7164 &    12.2637 & 1.33404 &                       1.3209 \\
%	      35 & 13.4210 & 3.36086 &       6.6735 &    10.0442 &    12.0270 & 1.35385 &                       1.3059 \\
%	      40 & 13.2226 & 3.36420 &       7.7248 &    10.4495 &    12.0379 & 1.34919 &                       1.2768 \\
%	      45 & 12.8445 & 3.47436 &       8.5539 &    10.8552 &    12.2773 & 1.42303 &                       1.4362 \\
%	      50 & 12.9245 & 3.58228 &       9.2702 &    11.2183 &    12.3990 & 1.40922 &                       1.3724 \\
%\bottomrule
%\end{tabular}
%\end{table}  
%
%\begin{figure}
%\centering
%\begin{tikzpicture}
%\begin{axis}[
%    y tick label style={
%        /pgf/number format/.cd,
%            fixed,   % po zakomentowaniu os rzednych jest indeksowana wykladniczo
%            fixed zerofill, % 1.0 zamiast 1
%            precision=1,
%        /tikz/.cd
%    },
%    x tick label style={
%        /pgf/number format/.cd,
%            fixed,
%            fixed zerofill,
%            precision=2,
%        /tikz/.cd
%    }
%]
%\addplot [domain=0.0:0.1] {rnd};
%\end{axis} 
%\end{tikzpicture}
%\caption{Podpis rysunku po rysunkiem.}
%\label{fig:2}
%\end{figure}
%
%
%\begin{figure}
%\begin{lstlisting}
%if (_nClusters < 1)
%	throw std::string ("unknown number of clusters");
%if (_nIterations < 1 and _epsilon < 0)
%	throw std::string ("You should set a maximal number of iteration or minimal difference -- epsilon.");
%if (_nIterations > 0 and _epsilon > 0)
%	throw std::string ("Both number of iterations and minimal epsilon set -- you should set either number of iterations or minimal epsilon.");
%\end{lstlisting}
%\caption{Przykład pseudokodu}
%\end{figure}


\section{Metodyka badań}

\subsection{Cel badania}

Celem badania jest sprawdzenie wydajności algorytmów wyszukujących na zbiorze
danych dostarczonego w celu wyszukania treści. Dodatkowym celem jest porównanie
działań zaimplementowanego programu z innymi, podobnymi rozwiązaniami.

\subsection{Zakres badania}

Zakres badań obejmuje porównanie prędkości algorytmów w celu ustalenia, który
z nich jest najszybszy pod względem czasu wykonania. Zostanie to ustalone na
mniejszym zbiorze rozpakowanych archiwów. Następnie na nierozpakowanym zbiorze
archiwów porównane zostaną narzędzia pod względem liczby wyszukań oraz prędkości
wyszukań.

\subsection{Hipoteza badań}

Hipotezą badań jest to, że kolejne algorytmy posiadające większe zużycie zasobów
na przygotowanie wyszukania, będą wykonywały się szybciej, niż te z mniejszym
zużyciem. Hipotezą pomocniczą jest to, iż im większy zbiór informacji zebrany
na podstawie łańcucha szukanego, tym większa prędkość algorytmu. Dodatkową hipotezą jest
to, iż wykorzystanie \english{Garbage Collectora} wpływa na stabilny czas
działania programu pomiędzy wykonaniami, oraz że czas wykonywania odczytów danych z dysku zajmuje
zdecydowaną ilość czasu.

% \section{Sposób przeprowadzenia badań}
\section{Badanie benchmarku algorytmów}

\begin{figure}[htbp]
  \centering
  \begin{lstlisting}
go test -test.bench=. -benchmem . -benchtime=1x -count=20

func BenchmarkMorisPrattWindowWord(b *testing.B) {
	var founds = []string{}
	mp := &MorisPratt{}
	filepath.Walk(DIR, WalkAndFindByAlgo(mp,
    &founds, []byte("window")))
	if len(founds) != 11598 {
		b.Fatal("test failed", len(founds), 11598)
	}
}
  \end{lstlisting}
  \caption{Przykład testu dla algorytmu MP}
  \label{fig:code:examplePerfTest}
\end{figure}
Badanie zostało przeprowadzone na maszynie autora, podczas działania środowiska
graficznego na Fedora 40. Procesor wykonujący operacje to Intel Core i7-6700K
w architekturze amd64.

Przeprowadzenie badań polegało na uruchomieniu komendy w pierwszej linii (rys. 
\ref{fig:code:examplePerfTest}) i wykonaniu funkcji na algorytmie Morisa Pratta. 
Wykonano 20 testów na wyszukaniu trzech słów, które mogły występować w zbiorze danych,
ze względu na wcześniej przeanalizowaną zawartość. Tymi słowami były 
'main', 'window', 'function'.

Zmienna \textbf{founds} przechowuje miejsce znalezionego 
ciągu wyszukiwanego, a zmienna \textbf{mp} to struktura przechowująca implementacje algorytmu MP oraz
bufor wcześniejszego procesowania (\textbf{BWP}) dla ciągu wyszukiwanego. Pierwsza implementacja nie 
posiadała tej struktury i \textbf{BWP} był obliczany przy każdym przebiegu algorytmu.
To znacznie wpłynęło na prędkość działania algorytmu Boyera-Moora, który 
posiadał największy rozmiar \textbf{BWP}.

\begin{Definition}\label{def:WalkFuncGolang}
\textbf{WalkFunc} jest to typ funkcji przyjmowany przez funkcje Walk w module filePath.
Funkcja ta przyjmuje 3 argumenty: ścieżkę, informacje o analizowanym pliku oraz
argument przyjmujący błąd i zwraca błąd. \newline \newline
\textit{type WalkFunc func(path string, info fs.FileInfo, err error) error}
\end{Definition}

W linijce 6 (rys. \ref{fig:code:examplePerfTest}) wykona się przejście (ang. 
\english{Walk}) po drzewie plików w \textbf{DIR}, który posiada ścieżkę do 
zbioru danych oraz przyjmuje funkcje zdefiniowaną jako \textbf{WalkFunc} jak w definicji
(def. \ref{def:WalkFuncGolang}). Z powodu potrzeby czytania tylko zawartości plików,
wykorzystano funkcje \textbf{WalkAndFindByAlgo}, która będzie czytała pliki, ale 
pozwoli algorytmom podanym w argumencie na przeszukanie zawartości w celu 
znalezienia słowa 'window'. \\ Po zakończeniu funkcji Walk otrzymano 
tablice znalezionych \textbf{founds}, wypełnioną miejscami, \\ w których wystąpiło 
znalezienie podanego ciągu. W liniach 8-10 każdy test posiada walidacje, aby wszystkie wyniki 
otrzymane przez algorytm, były zgodne z wcześniej ustaloną sumą.

\begin{figure}[htbp]
  \centering
  \begin{lstlisting}
goos: linux
goarch: amd64
pkg: github.com/gadzbi123/algorytmy/regular
cpu: Intel(R) Core(TM) i7-6700K CPU @ 4.00GHz
BenchmarkMorisPrattFunction-8 1	1041257510 ns/op 264623392 B/op 198976 allocs/op
BenchmarkMorisPrattFunction-8 1	1043653365 ns/op 264645080 B/op 198994 allocs/op
BenchmarkMorisPrattFunction-8 1	1040809273 ns/op 264632096 B/op 198971 allocs/op
BenchmarkMorisPrattFunction-8 1	1043999476 ns/op 264656192 B/op 199008 allocs/op
BenchmarkMorisPrattFunction-8 1	1047795718 ns/op 264641272 B/op 199006 allocs/op
BenchmarkKurtMorisPrattFunction-8 1	1059705156 ns/op 264679568 B/op 199007 allocs/op
BenchmarkKurtMorisPrattFunction-8 1	1044558720 ns/op 264704264 B/op 199016 allocs/op
BenchmarkKurtMorisPrattFunction-8 1	1069466845 ns/op 264722128 B/op 199032 allocs/op
BenchmarkKurtMorisPrattFunction-8 1	1062064344 ns/op 264666880 B/op 199024 allocs/op
BenchmarkKurtMorisPrattFunction-8 1	1062586497 ns/op 264697544 B/op 199018 allocs/op
BenchmarkBoyerMooreFunction-8 1	1163758449 ns/op 264251408 B/op 193795 allocs/op
BenchmarkBoyerMooreFunction-8 1	1142778080 ns/op 264249440 B/op 193831 allocs/op
BenchmarkBoyerMooreFunction-8 1	1127766499 ns/op 264255336 B/op 193817 allocs/op
BenchmarkBoyerMooreFunction-8 1	1169790667 ns/op 264177232 B/op 193775 allocs/op
BenchmarkBoyerMooreFunction-8 1	1128862027 ns/op 264270616 B/op 193811 allocs/op
  \end{lstlisting}
  \caption{Przykładowy rezultat performance}
  \label{fig:perfTestResults}
\end{figure}

W rezultacie wykonania otrzymano dane o czasie przebiegu funkcji, ilości 
alokacji oraz ile bajtów wykorzystano na operacje (rys. \ref{fig:perfTestResults}).
Zebrane dane zostały zaprezentowane oraz omówione w sekcjach 
\ref{rozdzial:porównanieBenchmarkowAlgos} oraz \ref{rozdzial:wynikiBenchmarkowAlgos}.

\section{Zbiór badań}

Zbiór danych (tab. \ref{tabela:typyMIMEdataset}) posiadał znaczną ilość 
plików pdf, które w niektórych przypadkach można było odczytać. Gdy pdf został
stworzony z dokumentu tekstowego takiego jak docx czy odt, to zawartość tekstowa
została zawarta w dokumencie pdf. Jeżeli natomiast pdf został stworzony ze skanu
książki, nie zapisała się treść tekstowa. Wtedy cała treść jest przechowana w 
postaci zdjęcia, które nie można odczytać użytym rozwiązaniem.

Możliwość odczytania zawartości daje narzędzie OCR (ang. \english{Optical Character Recognition}).
Narzędzie może służyć do oczytania zawartości plików pdf oraz tekstu z obrazów.
Takie rozwiązanie nie zostanie użyte w pracy, gdyż praca nie skupia się na 
algorytmach sztucznej inteligencji.

Pliki audio to piosenki oraz podcasty, których nie można łatwo odczytać algorytmem.
Do oczytania treści z takich plików można wykorzystać narzędzia dokonujące 
trankrypcji, czyli konwertujące rozpoznaną mowę na tekst, jednak te rozwiązania bazują 
na sztucznej inteligencji, które nie są przedmiotem pracy.

Kolejnym problemem okazało się odczytanie plików formatu doc, które są starym 
formatem dokumentów wykorzystywanych przez Microsoft i ich zakodowana treść nie
jest łatwa do odczytu. W odróżnieniu od formatu docx, który jest archiwum, 
narzędzie nie podejmie się odczytania plików doc. Z uwagi na to, że archiwum danych
jest dość stare, nie wystąpiły tam dokumenty formatu docx. Gdyby wystąpił można
by odczytać zawartość archiwów docx w ten sam sposób jak w przypadku innych 
archiwów.

Niestety w przypadku starych plików doc, nie ma możliwości rozpakowania treści
pliku i otrzymania zawartości. Dodatkowo pliki posiadają nietypowe kodowania,
co powoduje dalsze skomplikowanie z odczytania ich treści.

Archiwa posiadają również różne algorytmy kompresji oraz różne sposoby zapisu \\ w zależności od
rozszerzenia np. zip, rar, 7z, tar. To powoduje, że należy wykorzystać wiele
metod konwersji tych plików do faktycznej struktury możliwej do odczytania. 
Biblioteka, którą wykorzystano nie obsługuje plików skompresowanych przez gzip.
To powoduje, że pliki z rozszerzeniem .gz nie będą otwierane.

Pobrane archiwa posiadały brakujące dane i to powodowało, że biblioteka konwertująca
archiwa miała problem z ich otwarciem. Z tego powodu część danych musiała być 
pominięta, aby program nie został przerwany przez SEGV. Wykorzystana biblioteka
musiała zostać niepoprawnie zaimplementowana, gdyż istnieją programy umiejące 
otworzyć te archiwa, choć nie wszystkie z tych narzędzi działały poprawnie.
To wymagało zmniejszenia zbioru przeszukiwanych danych z archiwum i ograniczenia
się do 15 GB danych (tab. \ref{tabela:typy-MIME-z-iloscia}).




Pierwszy test wydajnościowy, który został przeprowadzony, sprawdzał wszystkie 
foldery, w których znajdowały się pliki. Za drugim razem ograniczono się tylko
do plików, które mogą posiadać oczekiwaną zawartość, odrzucając zatem część 
plików ze zbioru. Wykonano testy na 3 algorytmach, gdzie odczytywano 5191 plików 
i łącznie 240 MB danych. Oto rezultaty określonych algorytmów.

\subsection{Porównanie czasów algorytmów}
\label{rozdzial:porównanieBenchmarkowAlgos}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{./images/GraphFirstAttempt.png}
    \caption{Wykres czasów bez gotowego bufora pliku oraz z ponowną 
    liczeniem (BWP).}
    \label{fig:GraphFirstAttempt}
\end{figure}

Algorytm Morisa-Pratta jest nieznacznie wolniejszy od algorytmu 
Kurta-Morisa-Pratta. Jest to spowodowane niewielką optymalizacją pomiędzy tymi 
dwoma algorytmami. Według danych na rysunku (rys. \ref{fig:GraphFirstAttempt}) można 
zauważyć, KMP w niektórych przypadkach jest wolniejszy, niż algorytm MP.

Algorytm Boyera-Moore'a wykorzystywany w takich narzędziach jak grep, ma 
wolniejszy czas egzekucji, co wynika z rysunku (rys. \ref{fig:GraphFirstAttempt}), ale 
algorytm może zostać poprawiony. \\ Z powodu błędnej implementacji, wykonywano
ponowną kalkulację BWP podczas otwarcia nowego pliku, choć szukana fraza pozostawała
taka sama. Wykorzystanie wcześniejszego przeliczonego bufora ponownie wpłyneło na znaczne
przyspieszenie algorytmu.

Implementacja BM, której wyniki można zobaczyć na wykresie (rys. \ref{fig:GraphFirstAttempt}) jest
znacznie wolniejsza od pozostałych algorytmów. Powodem jest spędzanie znacznej
cześć czasu na stworzeniu tablicy wcześniejszego procesowania. Wiadome jest, że zawsze 
sprawdzany jest ten sam ciąg we wszystkich plikach w folderze. Istnieje możliwość 
stworzenia tablicy wcześniejszego procesowania przy pierwszym użyciu algorytmu, a następnie
wykorzystanie tej tablicy we wszystkich odczytach.

\begin{figure}[htbp]
    \includegraphics[width=\textwidth]{./images/GraphPreAllocBM.png}
    \caption{Wykres czasów bez statycznego bufora pliku z jednokrotną kalkulacją
     BWP w implementacji algorytmu Boyera-Moore'a. }
    \label{fig:GraphPreAllocBM}
\end{figure}

Na następnym wykresie (rys. \ref{fig:GraphPreAllocBM}) można zauważyć poprawę, gdy
implementacja algorytmu Boyer-Moora wykorzystuje ten sam bufor wcześniejszego procesowania, \\
a pozostałe algorytmy tworzą go od nowa, kiedy otwierany jest kolejny plik. Celem 
takiej implementacji było uzyskanie informacji o wpływie ponownego wykorzystania
bufora wcześniejszego procesowania na czas wykonania. 

Aby sprawdzić faktyczne wyniki, należało zaimplementować ponowne wykorzystanie
bufora wcześniejszego procesowania dla wszystkich algorytmów, a nie tylko dla BM.
Wyniki z drugiego wykresu potwierdziły wartość ponownego użycia bufora
wcześniejszego procesowania w prędkości wykonania algorytmu.

\begin{figure}[htbp]
    \includegraphics[width=\textwidth]{./images/GraphStaticPreallocAndFileBuffer.png}
    \caption{Wykres czasów ze statycznym buforem pliku oraz jednokrotną kalkulacją BWP dla każdego algorytmu.}
    \label{fig:GraphStaticPreallocAndFileBuffer}
\end{figure}

Ostatni wykres (rys. \ref{fig:GraphStaticPreallocAndFileBuffer}) przedstawia implementację
wykorzystującą ponownie bufor wcześniejszego procesowania, jak i bufor przechowujący plik.
Bufor wcześniejszego procesowania był przydzielany przy każdym otwarciu nowego pliku,
co powodowało, że ten bufor mógł być zbierany przez \english{Garbage Collector}.
W przypadku użycia stałego bufora zapewniamy, że program nie będzie się pozbywał
bufora, co uniknie proszenia o pamięć systemu. Gdy na początku programu utworzymy
bufor przechowywania pliku sami (nie polegając na optymalizacji języka), algorytm Boyera-Moore'a
odnotował 5 \% poprawę jak na rysunku (rys. \ref{fig:GraphStaticPreallocAndFileBuffer}) w stosunku do poprzedniej implementacji.

Niestety statyczny bufor przechowujący plik, należy alokować, znając rozmiar 
największego pliku w folderze, który wynosił 11 MB. Było tak, gdyż odrzucaliśmy
obrazy. Można przed rozpoczęciem algorytmu sprawdzać rozmiar maksymalny 
pliku, ale to wydłuży czas działania.

Istnieje też sytuacja, w której nie powinno się ustawiać największego rozmiaru, ponieważ nie
jest on znany w zbiorze. Podanie zbyt małej ilość na bufor pliku spowoduje,
że nie zostaną uzyskane wszystkie wyniki z pliku, gdyż nie zmieści się on w buforze pamięci statycznej.

Można wykorzystać pamięć dynamicznie przydzielaną i w przypadku zbyt małego 
bufora dla danych z pliku, ustawić nowy rozmiar równy zawartości pliku.
Zmniejszy to ilość alokowania nowego bufora, ale nie będzie to aż tak efektywne
w szybkim wyszukiwaniu danych, ponieważ znacząco zwiększy to czas działania
Garbage Collectora.

W badaniu porównawczym dla programów w następnej sekcji zdecydowano się na
czytanie pojedynczej linii z pliku, który skanujemy. Niestety to podejście
powodowało taki sam problem jak ten w przypadku bufora pamięci statycznej.

\subsection{Omówienie otrzymanych wyników}
\label{rozdzial:wynikiBenchmarkowAlgos}

\begin{figure}[htb]
    \centering
    \includegraphics[width=0.7\textwidth]{./images/benchstat-results-sumup.png}
    \caption{Obraz przedstawiający wynik działania programu 'benchstat'}
    \label{fig:benchstatResults}
\end{figure}

Otrzymane wyniki z testów wydajności algorytmów zestawiono z przedstawionych
danych otrzymanych z programu \textbf{benchstat} \ref{fig:benchstatResults}.
Program pozwolił na zorganizowanie 
danych przedstawionych na rysunku \ref{fig:perfTestResults}.

Z wyjścia programu \textbf{benchstat} wynika, że średnia odchylenia standardowego
wynosi około 3 \%, wiec nie została przedstawiona na wykresach 
\ref{fig:GraphFirstAttempt}, 
\ref{fig:GraphPreAllocBM},
\ref{fig:GraphStaticPreallocAndFileBuffer}.

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth]{./images/tabela-wyników-algo-all.png}
    \caption{Obraz przedstawiający wynik dla wszystkich algorytmów i ich iteracji.}
    \label{fig:algoAllTabela}
\end{figure}

W tabeli przedstawiono wyniki dla każdego z algorytmów, a wyniki podzielono
na liczbę znaków testowanego słowa \ref{fig:algoAllTabela}. Kolejne wiersze
przedstawiają wyniki, gdy nie zastosowano \textbf{BWP}, zastosowano \textbf{BWP}
jedynie dla algorytmu Boyera-Moore'a oraz kiedy wykorzystano \textbf{BWP} dla
wszystkich algorytmów. Dodatkowo w ostatnim wierszu dodano bufor dla 
przechowywanego pliku. 

\begin{figure}[htb]
    \centering
    \includegraphics[width=0.7\textwidth]{./images/tabela-algo-4-znaki.png}
    \caption{Obraz przedstawiający wynik dla 4 znaków wszystkich algorytmów.}
    \label{fig:algo4znakiTabela}
\end{figure}

Implementacja algorytmu Morisa-Pratta dla konfiguracji bez bufora, okazała się
najszybsza spośród wszystkich algorytmów. Najkrótszy czas wykonania został
oznaczony na ciemno zielono w tej iteracji algorytmów \ref{fig:algo4znakiTabela}.

Implementacja z buforem wcześniejszego procesowania spowodowała znaczne
przyspieszenie algorytmu BM w drugiej iteracji (kolor jasny czerwony). Nie zmieniono implementacji
pomiędzy testami w pierwszej i drugiej iteracją dla algorytmów MP i KMP.
Otrzymane wyniki pomiędzy dwoma iteracjami mieszczą się w średniej odchylenia 
standardowego słupka błędu. 

Z powodu znacznego przyspieszenia wykonania algorytmu BM, zdecydowano się na
dodanie \textbf{BWP} w 3 iteracji dla wszystkich algorytmów. Pomimo dodania jedynie 
statycznego bufora pliku dla BM, algorytm ten wciąż wykonywał się znacznie
szybciej od pozostałych rozwiązań (kolor czerwony). W trzeciej iteracji dodano implementację 
\textbf{BWP} dla MP \\ i KMP. Dodatkowo wprowadzono bufor statyczny
plików dla wszystkich algorytmów, aby zmniejszyć
prawdopodobieństwo dealokacji bufora pliku.

\begin{figure}[htb]
    \centering
    \includegraphics[width=0.7\textwidth]{./images/tabela-algo-6-znakow.png}
    \caption{Obraz przedstawiający wynik dla 6 znaków wszystkich algorytmów.}
    \label{fig:algo6znakowTabela}
\end{figure}

Dla 6 znaków wyniki prezentują się podobnie jak dla czterech
\ref{fig:algo6znakowTabela}. Ponownie algorytm MP wygrywa nieznacznie z KMP 
(zielony kolor), jednak po wprowadzeniu \textbf{BWP} i bufora pliku algorytm BM
wciąż ma przewagę szybkości wyszukiwania (kolor czerwony).

\begin{figure}[htb]
    \centering
    \includegraphics[width=0.7\textwidth]{./images/tabela-algo-8-znakow.png}
    \caption{Obraz przedstawiający wynik dla 8 znaków wszystkich algorytmów.}
    \label{fig:algo8znakowTabela}
\end{figure}

W przypadku 8 znaków czas wykonania algorytmów MP i KMP jest identyczny dla
pierwszej iteracji (kolor fioletowy \ref{fig:algo8znakowTabela}). Algorytm 
BM wykonuje się szybciej w drugiej \\ i trzeciej iteracji, dokładnie tak samo,
jak w poprzednich przypadkach.

\begin{figure}[htb]
    \centering
    \includegraphics[width=0.7\textwidth]{./images/tabela-algo-srednia.png}
    \caption{Obraz przedstawiający wynik średnie znaków wszystkich algorytmów.}
    \label{fig:algoAvgTabela}
\end{figure}

Zestawiając wyniki w postaci średniej ze wszystkich ilości znaków, można
porównać prędkości algorytmów w całości w zależności od iteracji 
\ref{fig:algoAvgTabela}. Z tabeli można wywnioskować, że dla wariantu bez
bufora, algorytm MP posiada najszybszą implementację. W przypadku zastosowania
\textbf{BWP}, który nie posiada znacznych wad, otrzymujemy dwukrotnie szybszy
algorytm w odniesieniu do BM oraz o 40\% szybszą implementację od 
wariantu bez \textbf{BWP} dla MP. 

Pomimo przyspieszenia algorytmów MP i KMP w trzeciej iteracji, nie udało się
dorównać prędkości BM z drugiej iteracji, a implementacja BM w trzeciej iteracji
uzyskała jeszcze lepszy wynik (czerwony i jasny czerwony \ref{fig:algoAvgTabela}).
Niestety zastosowanie bufora statycznego pliku, nie zwiększa znacznie prędkości
wykonywania obu algorytmów, a wymaga od użytkownika programu informacji o 
największym pliku ze zbioru przeszukiwanego. \\ Z tego powodu w przypadku badania
archiwów, zdecydowano się na wykorzystanie algorytmu z \textbf{BWP} bez
bufora pliku.

\section{Badanie ilość otrzymanych wyników z programów dla zbioru archiwów}

\begin{table}[p]
    \centering
    \begin{tabular}{|l|l|l|}
        \hline
        \textbf{Typ MIME} & \textbf{Rozmiar (w KB)} & \textbf{Ilość plików}\\
        \hline
application/zip & 9312014,35 & 236 \\
audio/mpeg & 2771693,64 & 541 \\
application/x-rar & 1358304,96 & 31 \\
application/vnd,ms-htmlhelp & 337207,65 & 100 \\
application/octet-stream & 302676,00 & 71 \\
image/jpeg & 228285,10 & 1347 \\
video/x-ms-asf & 223755,41 & 15 \\
image/vnd,djvu & 174702,98 & 24 \\
application/postscript & 84778,60 & 442 \\
application/x-ace-compressed & 83686,03 & 3 \\
application/gzip & 72011,68 & 58 \\
image/gif & 38853,47 & 1622 \\
text/html & 38485,94 & 1788 \\
application/msword & 29155,00 & 75 \\
audio/ogg & 24242,73 & 25 \\
application/x-tar & 20940,00 & 18 \\
application/x-dosexec & 9318,01 & 2 \\
audio/x-wav & 9180,17 & 1 \\
application/x-bzip2 & 6383,85 & 5 \\
text/rtf & 4710,93 & 2 \\
application/mac-binhex40 & 4704,44 & 2 \\
text/x-c++ & 4021,66 & 347 \\
video/x-msvideo & 3731,00 & 1 \\
application/vnd,ms-powerpoint & 3420,50 & 1 \\
text/x-c & 987,73 & 345 \\
text/plain & 858,96 & 136 \\
text/x-tex & 748,25 & 64 \\
application/winhelp & 216,03 & 1 \\
application/pdf & 112,13 & 1 \\
image/x-portable-greymap & 54,24 & 5 \\
text/x-diff & 45,52 & 2 \\
application/x-matlab-data & 40,19 & 1 \\
message/rfc822 & 31,62 & 1 \\
text/xml & 23,51 & 1 \\
application/x-shockwave-flash & 21,97 & 1 \\
application/x-ole-storage & 20,00 & 1 \\
application/x-winhelp & 16,43 & 1 \\
text/x-makefile & 10,37 & 7 \\
image/x-xfig & 7,15 & 3 \\
application/javascript & 6,91 & 1 \\
application/x-wine-extension-ini & 2,53 & 4 \\
text/x-perl & 1,92 & 1 \\
inode/x-empty & 0,00 & 20 \\
        \hline
Total & 15149469,59 & 7353 \\
        \hline
    \end{tabular}
    \caption{Ilość danych na podstawie typu MIME}
    \label{tabela:typy-MIME-z-iloscia}
\end{table}

W zbiorze archiwów znajdowało się 15 GB danych różnego rodzaju. Tabela 
przestawia hierarchiczną listę typów MIME (tab. \ref{tabela:typy-MIME-z-iloscia}).

Wybrano kilka narzędzi, które będą porównywane pod względem liczby wyszukiwań
oraz ich prędkości. Narzędzia, które zachowują się podobnie do implementacji
autora do \textbf{ugrep} (ug), \textbf{zgrep} oraz \textbf{ripgrep} (rg). 

\begin{figure}[htbp]
\centering
\includegraphics[width=1\textwidth]{./images/ugrep-errors.png}
\caption{Niepoprawne działanie programu ugrep dla archiwów pobranych z chmury}
\label{fig:ugrepErrors}
\end{figure}

Wiele z tych narzędzi nie działało poprawnie, gdy próbowano odczytać zawartość
archiwów. Przykładowo narzędzie ugrep (rys. \ref{fig:ugrepErrors}) nie rozpoznawało 
metody kompresji plików zip, co spowodowało, że nie otrzymano ani 
jednego rezultatu z programu. To powoduje, że narzędzie zostanie wykluczone z 
dalszej analizy.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{./images/zgrep-errors.png}
    \caption{Niepoprawne działanie programu zgrep z pomocą finda}
    \label{fig:zgrepErrors}
    \end{figure}

Możliwym rozwiązaniem byłoby rozpakowanie wszystkich plików innym narzędziem, np.
7z. Następnie wymaga to przeszukanie rozpakowanego pliku oraz rozpakowanie 
zawartego w nim kolejnego archiwum. Po wykonaniu takiego działania można 
odczytać zawartość, co znacznie wydłużyłoby czas działania. Takie podejście również
komplikuje testowanie takiego rozwiązania, bo wykonywane są różne programy, 
które wzajemnie na siebie oczekują. 

\textit{Narzędzie powinno być w stanie samo 
rozpakować i wyszukać wszystkie frazy poszukiwane. Dodatkowo narzędzie powinno
znajdować frazy zaraz po rozpakowaniu pliku i nie powinno czekać na rozpakowanie
wszystkich archiwów, aby przeszukiwać ich zawartość.}

Kolejne z wymienionych narzędzi również nie spełnia wymagań. Narzędzie \textbf{zgrep} nie pozwala
na rekurencyjne wyszukiwanie danych w folderach, w których znajdują się archiwa.
Nawet zastosowanie pomocniczego narzędzia \textbf{find} w celu wykonania zadania,
powoduje, że program nie jest w stanie przeskanować archiwów (rys. \ref{fig:zgrepErrors}).

Otrzymany błąd sugeruje, że długość danych w archiwum nie jest zgodna. Dodatkowo
wyświetlono informacje o błędzie w wartości cyklicznej kontroli nadmiarowej CRC
(ang. \english{Cyclic Redundancy Check}). Ta wartość to system sum kontrolnych
pozwalający na wykrycie błędów zmagazynowanych danych. Narzędzie \textbf{zgrep} nie pozwala 
rozpakować i przeszukać zawartości szukanych archiwów.

\begin{figure}[htbp]
\centering
\includegraphics[width=1\textwidth]{./images/przykład-otwarcia-archiwów.png}
\caption{Przykład otwarcia archiwów przez program graficzny Engrampa}
\label{fig:engrampaExample}
\end{figure}

Archiwa jednak są możliwe do otworzenia przez program graficzny Engrampa \cite{bib:internet:EngrampaArchives}.
Choć wszystkie pliki zostały odczytane, oznacza to, że istnieje możliwość pozyskania
części zawartości (rys. \ref{fig:engrampaExample}).

Narzędzie graficzne nie będzie brane pod uwagę do badania, zostało jedynie podane
jako przykład poprawności archiwów.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.7\textwidth]{./images/ripgrep-result-main.png}
\caption{Przykładowy rezultat wykonania komendy ripgrep ze zmierzonym czasem}
\label{fig:ripgrepResultMain}
\end{figure}

Narzędzie \textbf{ripgrep} pozwala na wyszukanie zawartości w archiwach i działa bardzo dobrze.
Narzędzie było w stanie wyszukać ogromną liczbę fraz 'main' we wszystkich plikach 
jak na rysunku (rys. \ref{fig:ripgrepResultMain}).
Narzędzie niestety nie posiada dokładnej lokalizacji, w której wystąpiło wyszukanie,
tylko jest w stanie wskazać miejsce w pliku skompresowanym.
Taki rezultat nie mówi, w którym pliku znajdują się frazy, a jedynie może znaleźć 
kontekst \\ w pliku lub podać ilość wystąpień.

Różnica ta jest znacząca w celu znalezienia frazy w konkretnym pliku. 
Implementacja \textbf{gsearch} pozwala na wyszukanie linii pliku, w którym fraza się znajduje. 

\begin{figure}[htbp]
\centering
\includegraphics[width=0.7\textwidth]{./images/rgSkippedmain.png}
\caption{Liczba wystąpień 'main' z pominięciem kilku archiwów}
\label{fig:ripgrepRemoveSkipped}
\end{figure}

Autorskim programem do przeszukiwania treści w archiwach jest \textbf{gsearch}. Od teraz
wszystkie odniesienia do implementacji będą odnosiły się do nazwy programu.

Gdy \textbf{gsearch} próbuje przeszukać archiwum z niepoprawną sumą kontrolną, program
zostaje wyłączony z powodu błędu. Program \textbf{gsearch} może wykonać pełne szukanie \\ w przypadku,
gdy suma kontrola plików archiwów jest poprawna.

Gdy \textbf{gsearch} przeszukuje archiwa nieuszkodzone, przedstawione na rysunku (rys. \ref{fig:ripgrepRemoveSkipped}),
to widać, że liczba wystąpień w \textbf{gsearch} jest większa. Poniżej znajduje się zestawienie
ilości znalezionych wystąpień dla wszystkich archiwów przeszukiwanych przez \textbf{rg},
pominiętych archiwów dla \textbf{rg} oraz pominiętych archiwów przeszukanych przez \textbf{gsearch}.

\begin{table}[htbp]
    \centering
    \begin{tabular}{|r|r|r|r|}
        \hline
        \textbf{Fraza (litery)} & \textbf{rg (25 GB archiw)} & \textbf{rg (15 GB)} &  \textbf{gsearch (15 GB)} \\
        \hline
        wan (3) & 34821 & 22951 & 20293 \\
        \hline
        main (4) & 107265 & 22521 & 23822 \\
        \hline
        window (6) & 16998 & 8251 & 9430 \\
        \hline
        analysis (8) & 3511 & 2168 & 1740 \\
        \hline
        book desc (9) & 6 & 3 & 3 \\
        \hline
        informatyka (11) & 1 & 1 & 5 \\
        \hline
        wInDoW (6) & 56760 & 20939 & 0 \\
        \hline
    \end{tabular}
    \caption{Tabela zestawienia wyników wyszukiwania konkretnych fraz dla programów}
    \label{tabela:iloscWyszukanDziekiProgramom}
\end{table}

Należy wspomnieć, iż jedno wystąpienie dla narzędzia \textbf{ripgrep} to pojawienie się frazy
w danej linijce. W ten sam sposób liczone jest znalezienie wystąpienia w \textbf{gsearch}.
Implementacja \textbf{gsearch} nie posiada wrażliwości na wielkość liter, dlatego nie 
jest testowana.

Tabela (tab. \ref{tabela:iloscWyszukanDziekiProgramom}) przedstawia wyniki ilości 
wystąpień fraz w zbiorze archiwów. Ponieważ implementacja \textbf{gsearch} nie potrafi
przeszukać określonych archiwów, zdecydowano się na zestawienie rezultatów
\textbf{ripgrepa} ze wszystkich archiwów, oraz z tego samego zbioru archiwów pominiętych. 

Należy zauważyć, że pozostałe programy (\textbf{ugrep}, \textbf{zgrep}) nie 
zostały zamieszczone \\ w tabeli, z powodu braku uzyskania wyników.
Każdy z tych programów miałby wartość 0 dla każdej frazy.

\begin{figure}[htbp]
    \centering
    \begin{tikzpicture}[scale=1.50]
        \begin{axis}[
        xlabel=Długość słowa,
        ylabel=Ilość znalezionych linii,
        grid, thick,
        legend pos=north east]
        \addplot[color=orange,mark=x]coordinates{
            (3,22951)
            (4,22521)
            (6,8251)
            (8,2168)
            (9,3)
            (11,3)
        };
        \addlegendentry{ripgrep};
        \addplot[color=blue,mark=x]coordinates{
            (3,20293)
            (4,23822)
            (6,9430)
            (8,1740)
            (9,3)
            (11,5)
        };
        \addlegendentry{gsearch};
        \end{axis}
    \end{tikzpicture}
    \caption{Wykres wystąpień linii z frazami w zależności od długości liter w słowie }
    \label{fig:wykresPorównaniaIlosciWystapień}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{./images/gsearch-result-informatyka.png}
    \caption{Zdjęcie przedstawia przykładowe wykonanie programu gsearch na słowie informatyka.}
    \label{fig:wykonanieProgramuGsearch}
\end{figure}

Ostatni wiersz pokazuje jakie znaczenie ma wyszukiwanie po wielkości liter 
(tab. \ref{tabela:iloscWyszukanDziekiProgramom}). Program \textbf{ripgrep} posiada 
możliwość ignorowania wielkości liter czego nie robi program gsearch. Jeżeli
nieznana jest dokładna wielkości liter frazy, to może to spowodować brak 
znalezienia frazy (rys. \ref{fig:wykresPorównaniaIlosciWystapień}). 

Na obrazie (rys. \ref{fig:wykonanieProgramuGsearch}) można zauważyć przykładowy
rezultat programu \textbf{gsearch}. Zapisany zostaje strumień wyjścia jako zawartość do pliku
przy użyciu programu \textbf{tee}. Następnie obliczana jest ilość znalezionych linii,
na podstawie zawartości pliku używając \textbf{wc -l}.

Program \textbf{ripgrep} nie jest w stanie znaleźć zawartości archiwów zagnieżdżonych \\ w
innych archiwach. Rozwiązuje ten problem gsearch i pozwala na wyszukanie 
znalezienie konkretnego pliku w którym fraza się znajduje.

\section{Porównanie prędkości wyszukiwania programów}

Porównane zostaną programy, które pozwoliły uzyskać oczekiwany rezultat i są to
\textbf{ripgrep} oraz implementowany \textbf{gsearch}. 
Porównanie szybkości wyszukiwania zostanie wykonane na pomniejszonym zbiorze,
aby porównanie czasów było sprawdzane na tym samym zbiorze, gdzie oba programy
są w stanie odczytać z nich dane.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{./images/example-hyperfine-run.png}
    \caption{Zdjęcie wyników testów hyperfine.}
    \label{fig:hyperfineExample}
\end{figure}

Porównanie zostanie przeprowadzone wykorzystując narzędzie \textbf{hyperfine}, które
jest bardzo dobre do testowania różnic pomiędzy szybkościami podobnych programów.
Przykładowy rezultat wykonania jednego testu daje dużo informacji i zostaje
zapisany do pliku csv (rys. \ref{fig:hyperfineExample}). Dwa programy \textbf{gseach} 
oraz \textbf{ripgrep} wykonują się jednokrotnie. Następnie otrzymano czas wykonania obu
programów i krótkie podsumowanie otrzymanych wyników. 

\begin{figure}[htbp]
    \centering
    \begin{tikzpicture}[scale=1.30]
        \node [color=orange] at (6,1) {$ripgrep$};
        \node [color=blue] at (6,5.2) {$gsearch$};
        \begin{axis}[
            xlabel=Długość słowa,
            ylabel=Czas znalezienia słów (s),
            grid, thick
]
        \addplot[color=orange, mark=x,error bars/.cd, y dir=both, y explicit]coordinates{
(3,0.6393700976599999)+=(0,0.007651709374308371)-=(0,0.007651709374308371)
(4,0.69975840454)+-(0,0.02174176683244841)
(6,0.6708412953200001)+-(0,0.04320545697230668)
(8,0.76563712796)+-(0,0.041486089097604)
(9,0.62396489284)+-(0,0.007851351947769116)
(11,0.6782059222)+-(0,0.04570502275958309)
        };
        \addplot[color=blue, mark=x,error bars/.cd, y dir=both, y explicit]coordinates{
(3,20.081044353359996)+-(0,0.4395975771554202)
(4,19.78817344134)+-(0,0.20913605765611032)
(6,19.25416691472)+-(0,0.21635912584660782)
(8,18.88328445046)+-(0,0.19096399774593745)
(9,18.916769088339997)+-(0,0.5162741966007814)
(11,18.5046544439)+-(0,0.17920383136563042)
        };
        \end{axis}
    \end{tikzpicture}
    \caption{Wykres czasów wyszukania fraz dwóch programów w zależności od ilości liter}
    \label{fig:wykresPorównaniaCzasówWyszukań}
\end{figure}

Prędkości wyszukiwania danych za pomocą funkcji \textbf{ripgrep} są znacznie większe niż te
za pomocą \textbf{gsearch} (rys. \ref{fig:wykresPorównaniaCzasówWyszukań}). Wynika to z
tego, że \textbf{ripgrep} wykonuje wyszukiwania z wykorzystaniem kilku wątków. Dodatkowo 
program \textbf{rg} ładuje pliki prosto do pamięci, natomiast program \textbf{gsearch} rozpakowuje
zawartość pliku archiwum do folderu, a następnie czyta zawartość każdego pliku.

Takie podejście było konieczne, gdyż Golang ma wbudowane większe ograniczenia w 
proces alokowania danych i tego ile danych może przechowywać w pamięci w danym momencie.

Wykorzystanie innego języka dającego większą swobodę w manipulowaniu pamięcią 
dałoby lepsze czasy wykonania, jednak wykorzystanie języka niskopoziomowego,
wiąże się \\ z większym czasem implementacji algorytmów oraz trudniejszym procesem
analizowania błędów.

Program \textbf{ripgrep} dla fraz o długości 3 lub mniejszych używa algorytmu Teddy. Ten algorytm
pozwala na załadowanie całej frazy do rejestru XMM i wykonania bitowego 
porównania małej frazy z zawartością danych przeszukiwanych.

\section{Narzędzie ripgrep, a pamięć tymczasowa}


\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\textwidth]{./images/ripgrep-clear-cache-slow.png}
    \caption{Przykład czasu wykonania narzędzia ripgrep z wyczyszczoną pamięcią
    podręczną i bez wyczyszczenia}
    \label{fig:ClearCacheRipgrep}
\end{figure}

Komenda \textbf{ripgrep} posiada bardzo nietypowe działanie w przypadku kolejnych wykonań 
programu. Po pierwszym wykonaniu programu dane z dysku są znacznie dłużej
wyszukiwane. Pomimo że program nie wykorzystuje operacji zachowania danych
w pamięci tymczasowej (cache), to system operacyjny przechowuje zawartość plików 
i ścieżki w RAM. To powoduje, że zanim \textbf{ripgrep} zacznie czytać treść z 
dysku, to sprawdza zawartość pamięci RAM. Gdy 
wyczyszczono cache jak na obrazie (rys. \ref{fig:ClearCacheRipgrep}),
zauważyć można znaczną pogorszenie rezultatów \textbf{ripgrep}. 

Pierwsza komenda zapewnia brak utraty
danych, a następnie druga komenda powoduje zapisanie pliku drop caches z wartością 3.
Ta komenda czyści wszystkie zapisane zawartości pliku oraz dane o odczytywanych
folderach i plikach.

Ta komenda powoduje spowolnienie działania obu programów, jednak w znacznie
mniejszym stopniu w przypadku \textbf{gsearch} niż \textbf{ripgrep} jak na wykresie (rys. \ref{fig:wykresPorównaniaCzasówWyszukańUncached}).
Można również zauważyć większe odchylenie standardowe czasów wyszukiwań dla \textbf{gsearch}, natomiast
ogólny czas działania programu jest o połowę krótszy niż w przypadku polecenia \textbf{ripgrep}.

\begin{figure}[htbp]
    \centering
    \begin{tikzpicture}[scale=1.30]
        \node [color=blue] at (6,1) {$gsearch$};
        \node [color=orange] at (6,4.8) {$ripgrep$};
        \begin{axis}[
        xlabel=Długość słowa,
        ylabel=Czas znalezienia słów (s),
        grid, thick]
        \addplot[color=orange, mark=x,error bars/.cd, y dir=both, y explicit]coordinates{
(3,150.6928509870)+-(0,0.5395975771554202)
(4,150.2652969279)+-(0,1.1823469234769377030)
(6,150.0637899279)+-(0,0.6528969286296298698)
(8,149.9745325373738)+-(0,1.189532878378378387)
(9,149.916769088339997)+-(0,0.842131516816698)
(11,149.5046544439)+-(0,0.9863929239459696)
        };
        \addplot[color=blue, mark=x*,error bars/.cd, y dir=both, y explicit]coordinates{
(3,48.081044353359996)+-(0,1.374358456463532)
(4,47.78817344134)+-(0,1.152637838)
(6,45.25416691472)+-(0,1.3674374846352352)
(8,44.88328445046)+-(0,1.26889999)
(9,43.916769088339997)+-(0,1.26626327888)
(11,43.5046544439)+-(0,1.17920383136563042)
        };
        \end{axis}
    \end{tikzpicture}
    \caption{Wykres czasów znalezienia fraz po wyczyszczeniu pamięci tymczasowej}
    \label{fig:wykresPorównaniaCzasówWyszukańUncached}
\end{figure}

\section{Wykorzystanie profilowania do oczytania charakterystyki programu}

\begin{figure}[htbp]
  \centering
  \begin{lstlisting}
f, _ := os.Create("profile.pprof")
pprof.StartCPUProfile(f)
defer pprof.StopCPUProfile()
  \end{lstlisting}
  \caption{Dodanie profilowania do programu gsearch}
  \label{fig:code:profilerGsearch}
\end{figure}

Można również sprawdzić charakterystykę programu gsearch dodając kod na początek 
wykonania programu (rys. \ref{fig:code:profilerGsearch}). Wykonanie programu na
słowie 'informatyka' utworzy plik profile.pprof. Ten plik można przejrzeć w 
przeglądarce wcześniej wykorzystując komendę \textbf{go tool pprof -http=localhost:8090 profile.pprof}.

\begin{figure}[htbp]
\centering
\includegraphics[width=1\textwidth]{./images/profiler1.png}
\caption{Zdjęcie profilu programu gsearch z użyciem narzedzia 'pprof'}
\label{fig:profilerGsearch1}
\end{figure}

Po wykonaniu komendy w przeglądarce otworzy się widok na graf programu (rys. \ref{fig:profilerGsearch1}).
Graf jest bardzo skomplikowany do analizy w przypadku, gdy program wykorzystuje rekursje do
przeszukiwania folderów i rozpakowywania zawartości.

Można zauważyć, że większość czasu programu wykorzystywana jest na operacje 
ekstrakcji archiwów i czytania archiwów. Sam algorytm przeszukujący (dolny lewy 
róg rys. \ref{fig:profilerGsearch1}) wykonuje się jedynie 0,72 sekundy.

\begin{figure}[htbp]
\centering
\includegraphics[width=1\textwidth]{./images/profiler2.png}
\caption{Zdjęcie pokazujące procent czasu wykonania 'runtime cgocall' w gsearch}
\label{fig:profilerGsearch2}
\end{figure}

Głównym ograniczeniem prędkości działania jest czas odczytywania zawartości z plików.
Funkcje 'runtime cgocall' stanowi znaczną część czasu
wykonywania programu (rys. \ref{fig:profilerGsearch2}), ponieważ wykonuje operacje
odczytu zawartości treści z dysku.